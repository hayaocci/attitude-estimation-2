#!/usr/bin/env python3
"""
train_dilated_hsv.py ‚Äï Research project trainer (Dilated ResNet + HSV version)
===================================================================
* Dilated Convolution„ÇíÊé°Áî®„Åó„ÄÅ„Éë„É©„É°„Éº„ÇøÊï∞„ÇíÂ¢ó„ÇÑ„Åï„Åö„Å´ÂèóÂÆπÈáé„ÇíÊã°Â§ß„ÄÇ
* ÂÖ•ÂäõÁîªÂÉè„Çí RGB „Åã„Çâ HSV „Å´Â§âÊèõ„Åó„Å¶Â≠¶Áøí„ÄÇ
* Gridding EffectÂØæÁ≠ñ„Å®„Åó„Å¶„ÄÅÂêÑStage„ÅßÁï∞„Å™„ÇãDilation Rate„ÇíÈÅ©Áî®„ÄÇ
* ÂπÖÁ∏ÆÂ∞è (WIDTH_MULT) „Åä„Çà„Å≥ sin„Éªcos 2 Âá∫ÂäõÂ≠¶Áøí„Å´ÂØæÂøú„ÄÇ
"""
from __future__ import annotations

import argparse, csv, json, math, random, sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List

import matplotlib; matplotlib.use("Agg")
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import yaml
from PIL import Image
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from tqdm import tqdm

# ============================================================
# Reproducibility helper
# ============================================================

def set_seed(seed: int):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

# ============================================================
# Angle helpers (roll only)
# ============================================================

def deg2rad(x: torch.Tensor | float):
    return x * math.pi / 180.0

def deg2sincos(x: torch.Tensor):
    x_rad = deg2rad(x)
    return torch.stack((torch.sin(x_rad), torch.cos(x_rad)), dim=-1)

def sincos2deg(v: torch.Tensor):
    rad = torch.atan2(v[..., 0], v[..., 1])
    deg = rad * 180.0 / math.pi
    return deg.remainder(360.0)

def circular_error(pred_deg: torch.Tensor, true_deg: torch.Tensor):
    diff = (pred_deg - true_deg + 180.0) % 360.0 - 180.0
    return diff.abs()

# ============================================================
# Dilated ResNet Implementation
# ============================================================

class DilatedBasicBlock(nn.Module):
    expansion = 1

    def __init__(self, in_ch, out_ch, stride=1, downsample=None, dilation=1):
        super().__init__()
        # k=3 „ÅÆÂ†¥Âêà„ÄÅpadding=dilation „Å®„Åô„Çã„Åì„Å®„ÅßËß£ÂÉèÂ∫¶„ÇíÁ∂≠ÊåÅ (stride=1ÊôÇ)
        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride=stride, 
                               padding=dilation, dilation=dilation, bias=False)
        self.bn1 = nn.BatchNorm2d(out_ch)
        self.relu = nn.ReLU(inplace=True)
        
        # 2Â±§ÁõÆ„ÇÇÂêåÊßò„ÅÆ dilation „ÇíÈÅ©Áî®
        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, stride=1, 
                               padding=dilation, dilation=dilation, bias=False)
        self.bn2 = nn.BatchNorm2d(out_ch)
        self.downsample = downsample

    def forward(self, x):
        identity = x
        out = self.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        if self.downsample is not None:
            identity = self.downsample(x)
        return self.relu(out + identity)


class ResNet18Dilated(nn.Module):
    """
    Gridding EffectÂØæÁ≠ñ„ÇíÊñΩ„Åó„ÅüÊã°ÂºµResNet18„ÄÇ
    ÂêÑStage„Åß Dilation Rate „Çí 1, 2, 4, 8 „Å®Â§âÂåñ„Åï„Åõ„ÄÅÂ∫ÉÂüü„Å™ÁâπÂæ¥„ÇíÂØÜ„Å´ÊäΩÂá∫„Åó„Åæ„Åô„ÄÇ
    """
    def __init__(self, in_ch: int = 3, out_dim: int = 2, width_mult: float = 1.0, 
                  hidden_dim: int = 256, dropout_p: float = 0.3):
        super().__init__()
        base_channels = np.array([64, 128, 256, 512])
        chs = np.maximum(1, (base_channels * width_mult).astype(int)).tolist()
        self.inplanes = chs[0]

        # Stem (ÈÄöÂ∏∏ÈÄö„Çä„ÅÆ 3x3)
        self.conv1 = nn.Conv2d(in_ch, chs[0], 3, 1, 1, bias=False)
        self.bn1 = nn.BatchNorm2d(chs[0])
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(3, 2, 1)

        # ÂêÑStage„Åß dilation „ÇíÂ§âÊõ¥ (Hybrid Dilated Convolution)
        self.layer1 = self._make_layer(chs[0], 2, stride=1, dilation=1)
        self.layer2 = self._make_layer(chs[1], 2, stride=2, dilation=2)
        self.layer3 = self._make_layer(chs[2], 2, stride=2, dilation=4)
        self.layer4 = self._make_layer(chs[3], 2, stride=2, dilation=8)

        # Head
        self.avgpool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Flatten(),
            nn.Linear(chs[3], hidden_dim),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout_p),
            nn.Linear(hidden_dim, out_dim),
        )

        total = sum(p.numel() for p in self.parameters())
        print(f"üèóÔ∏è ResNet18Dilated (width={width_mult}): {total/1e6:.2f}M params")

    def _make_layer(self, planes, blocks, stride, dilation):
        downsample = None
        if stride != 1 or self.inplanes != planes:
            downsample = nn.Sequential(
                nn.Conv2d(self.inplanes, planes, 1, stride, bias=False),
                nn.BatchNorm2d(planes),
            )
        
        layers = []
        layers.append(DilatedBasicBlock(self.inplanes, planes, stride, downsample, dilation))
        self.inplanes = planes
        for _ in range(1, blocks):
            layers.append(DilatedBasicBlock(self.inplanes, planes, dilation=dilation))
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.maxpool(self.relu(self.bn1(self.conv1(x))))
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        x = self.avgpool(x)
        v = self.fc(x)
        # ËßíÂ∫¶Áî®„Éô„ÇØ„Éà„É´ L2 Ê≠£Ë¶èÂåñ
        v = v.view(v.size(0), -1, 2)
        v = nn.functional.normalize(v, dim=2)
        return v.view(v.size(0), -1)

# ============================================================
# Dataset (Updated for HSV)
# ============================================================

class ImageRegressionDataset(Dataset):
    def __init__(self, img_dir: Path | str, img_size: int, normalize: bool = True, use_hsv: bool = True):
        self.img_dir = Path(img_dir)
        self.use_hsv = use_hsv
        label_csv = self.img_dir.parent / "labels.csv"
        if not label_csv.exists():
            raise FileNotFoundError(f"Label CSV not found: {label_csv}")
        df = pd.read_csv(label_csv)
        self.paths = df["filename"].apply(lambda x: self.img_dir / x).tolist()
        self.targets_deg = df["roll"].astype(np.float32).values

        # HSV/RGBÂÖ±ÈÄö„ÅÆÊ≠£Ë¶èÂåñ„ÄÇToTensor()„Åß[0, 1]„Å´„Å™„Çã„Åü„ÇÅ„ÄÅ(x-0.5)/0.5 „Åß [-1, 1] „Å´Â§âÊèõ
        mean, std = ([0.5], [0.5]) if normalize else ([0.0], [1.0])
        
        transform_list = [transforms.Resize((img_size, img_size))]
        if self.use_hsv:
            # PIL Image„ÅÆÊÆµÈöé„ÅßHSV„Å´Â§âÊèõ
            transform_list.append(transforms.Lambda(lambda x: x.convert("HSV")))
        
        transform_list.append(transforms.ToTensor())
        transform_list.append(transforms.Normalize(mean=mean * 3, std=std * 3))
        
        self.transform = transforms.Compose(transform_list)

    def __len__(self):
        return len(self.paths)

    def __getitem__(self, idx):
        img = Image.open(self.paths[idx]).convert("RGB")
        img = self.transform(img)
        target_deg = torch.tensor(self.targets_deg[idx])
        return img, target_deg, self.paths[idx].name

# ============================================================
# Factory & Config Helpers
# ============================================================

def parse_width_from_name(name: str, default: float = 1.0):
    if "_" not in name: return default
    try:
        token = name.split("_")[-1]
        return float(token.replace("p", "."))
    except ValueError: return default

def get_model(name: str, out_dim: int, hidden_dim: int = 256, dropout_p: float = 0.3):
    width = parse_width_from_name(name, 1.0)
    return ResNet18Dilated(3, out_dim, width_mult=width, hidden_dim=hidden_dim, dropout_p=dropout_p)

def load_configs(cfg_path: str | Path) -> List[Dict]:
    with open(cfg_path, encoding="utf-8") as f:
        cfgs = yaml.safe_load(f)
    processed = []
    for cfg in cfgs:
        train_root = Path(cfg.get("TRAIN_DATASET_ROOT", cfg["DATASET_ROOT"]))
        valid_root = Path(cfg.get("VALID_DATASET_ROOT", cfg["DATASET_ROOT"]))
        size, mode, resize_mode = int(cfg["IMG_SIZE"][0]), cfg["INPUT_MODE"], cfg.get("RESIZE_MODE", "area")
        
        def build(root: Path, split: str):
            return str(root / "cache" / mode / f"sz{size}_{resize_mode}" / split / "imgs")

        cfg["TRAIN_DIR"], cfg["VALID_DIR"] = build(train_root, "train"), build(valid_root, "valid")
        cfg["EVAL_DIR"], cfg["RESIZE_MODE"] = cfg["VALID_DIR"], resize_mode
        cfg["_TRAIN_ROOT"], cfg["_VALID_ROOT"] = str(train_root), str(valid_root)
        processed.append(cfg)
    return processed

def make_log_dir(cfg: Dict) -> Path:
    train_tag, valid_tag = Path(cfg["_TRAIN_ROOT"]).name, Path(cfg["_VALID_ROOT"]).name
    dataset_tag = f"{train_tag}_vs_{valid_tag}" if train_tag != valid_tag else train_tag
    # HSV„É¢„Éº„Éâ„Åß„ÅÇ„Çã„Åì„Å®„Çí„Éï„Ç©„É´„ÉÄÂêç„Å´Âê´„ÇÅ„Çã
    hsv_tag = "hsv" if cfg.get("USE_HSV", True) else "rgb"
    mode_size = f"{cfg['INPUT_MODE']}_{hsv_tag}_sz{cfg['IMG_SIZE'][0]}_{cfg['RESIZE_MODE']}"
    run_id = f"{datetime.now().strftime('%Y%m%d_%H%M')}_{cfg['id']}"
    run_dir = Path("logs") / dataset_tag / cfg["MODEL_NAME"] / mode_size / run_id
    run_dir.mkdir(parents=True, exist_ok=True)
    with open(run_dir / "config_used.yaml", "w", encoding="utf-8") as f:
        yaml.safe_dump(cfg, f, allow_unicode=True)
    for sub in ["checkpoints", "figs"]: (run_dir / sub).mkdir(exist_ok=True)
    return run_dir

# ============================================================
# Training Logic
# ============================================================

def train_epoch(model, loader, optimizer, criterion, device, sincos_mode):
    model.train()
    total = 0.0
    for imgs, tgt_deg, _ in loader:
        imgs = imgs.to(device)
        optimizer.zero_grad()
        if sincos_mode:
            tgt_vec = deg2sincos(tgt_deg).to(device)
            loss = criterion(model(imgs), tgt_vec)
        else:
            loss = criterion(model(imgs).squeeze(), tgt_deg.to(device))
        loss.backward(); optimizer.step()
        total += loss.item() * imgs.size(0)
    return total / len(loader.dataset)

def validate(model, loader, criterion, device, sincos_mode):
    model.eval()
    total, mae = 0.0, []
    with torch.no_grad():
        for imgs, tgt_deg, _ in loader:
            imgs = imgs.to(device)
            outputs = model(imgs)
            if sincos_mode:
                total += criterion(outputs, deg2sincos(tgt_deg).to(device)).item() * imgs.size(0)
                err = circular_error(sincos2deg(outputs.cpu()), tgt_deg)
            else:
                total += criterion(outputs.squeeze(), tgt_deg.to(device)).item() * imgs.size(0)
                err = (outputs.squeeze().cpu() - tgt_deg).abs()
            mae.extend(err.numpy())
    return total / len(loader.dataset), float(np.mean(mae))

def plot_training_curves(train_losses, val_losses, val_maes, out_dir: Path):
    epochs = np.arange(1, len(train_losses) + 1)
    fig, ax = plt.subplots(1, 2, figsize=(12, 4))
    ax[0].plot(epochs, train_losses, label="train_loss")
    ax[0].plot(epochs, val_losses, label="val_loss")
    ax[0].set_title("Loss"); ax[0].legend()
    ax[1].plot(epochs, val_maes, label="val_MAE", color="orange")
    ax[1].set_title("MAE"); ax[1].legend()
    plt.savefig(out_dir / "figs" / "curves.png"); plt.close()

# ============================================================
# Main Experiment Driver
# ============================================================

def run_experiment(cfg):
    set_seed(cfg["SEED"])
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    run_dir = make_log_dir(cfg)

    img_sz = cfg["IMG_SIZE"][0]
    use_hsv = cfg.get("USE_HSV", True) # YAML„Å´Ë®òËºâ„Åå„Å™„ÅÑÂ†¥Âêà„ÅØ„Éá„Éï„Ç©„É´„Éà„ÅßTrue

    train_ld = DataLoader(ImageRegressionDataset(cfg["TRAIN_DIR"], img_sz, use_hsv=use_hsv), 
                          cfg["BATCH_SIZE"], True, num_workers=cfg["NUM_WORKERS"])
    valid_ld = DataLoader(ImageRegressionDataset(cfg["VALID_DIR"], img_sz, use_hsv=use_hsv), 
                          cfg["BATCH_SIZE"], False, num_workers=cfg["NUM_WORKERS"])

    single_roll = cfg["OUTPUT_AXES"] == ["roll"]
    model = get_model(cfg["MODEL_NAME"], 2 if single_roll else len(cfg["OUTPUT_AXES"]), 
                      cfg["HIDDEN_DIM"], cfg["DROPOUT_P"]).to(device)

    criterion = nn.SmoothL1Loss() if single_roll else nn.MSELoss()
    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg["MAX_LR"], weight_decay=cfg["WEIGHT_DECAY"])
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg["EPOCHS"])

    train_losses, val_losses, val_maes, best_mae, no_improve = [], [], [], float("inf"), 0
    
    print(f"üöÄ Starting Experiment: {cfg['id']} (HSV={use_hsv})")
    for ep in range(1, cfg["EPOCHS"] + 1):
        tl = train_epoch(model, train_ld, optimizer, criterion, device, single_roll)
        vl, mae = validate(model, valid_ld, criterion, device, single_roll)
        scheduler.step()
        
        train_losses.append(tl); val_losses.append(vl); val_maes.append(mae)
        print(f"Epoch {ep:03d}: train={tl:.4f} valid={vl:.4f} MAE={mae:.3f}")
        
        if mae < best_mae:
            best_mae, no_improve = mae, 0
            torch.save(model.state_dict(), run_dir / "checkpoints" / "best.pth")
        else:
            no_improve += 1
        
        if cfg.get("EARLY_STOP") and no_improve >= int(cfg.get("PATIENCE", 10)):
            print(f"Early stop at {ep}"); break

    plot_training_curves(train_losses, val_losses, val_maes, run_dir)
    print(f"Finished exp {cfg['id']}: Best MAE={best_mae:.3f}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", default="config.yaml")
    args = parser.parse_args()
    for cfg in load_configs(args.config):
        try: run_experiment(cfg)
        except Exception as e: 
            import traceback
            traceback.print_exc()
            print(f"[ERROR] Exp {cfg['id']} failed: {e}", file=sys.stderr)